{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import dill\n",
    "\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Lambda\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Input\n",
    "from keras.optimizers import SGD, Adam, Adagrad, RMSprop\n",
    "from keras.regularizers import l2, activity_l2\n",
    "from keras.models import Model,Sequential\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_model(inp_shape):\n",
    "    model=Sequential()\n",
    "    \n",
    "    model.add(Convolution2D(3, 3, 3, activation=\"relu\",W_regularizer=l2(0.01),b_regularizer=l2(0.01),input_shape=inp_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Convolution2D(3, 3, 3, activation=\"relu\",W_regularizer=l2(0.01),b_regularizer=l2(0.01),input_shape=()))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(10,activation=\"relu\",W_regularizer=l2(0.01),b_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1,activation=\"sigmoid\",W_regularizer=l2(0.01),b_regularizer=l2(0.01)))\n",
    "    \n",
    "    #SGD(lr=0.01, momentum=0.8, decay=0.0, nesterov=False)\n",
    "    opt=RMSprop()\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 28, 18, 3)     30          convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 14, 9, 3)      0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 14, 9, 3)      0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 12, 7, 3)      84          dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 6, 3, 3)       0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 6, 3, 3)       0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 54)            0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 10)            550         flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 10)            0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             11          dropout_3[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 675\n",
      "____________________________________________________________________________________________________\n",
      "[<tf.Tensor 'convolution2d_input_1:0' shape=(?, 30, 20, 1) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "model=get_model((30,20,1))\n",
    "model.summary()\n",
    "print model.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2680, 600)\n",
      "(2680,)\n",
      "float64\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "data_path='data/ser_datasets/big_set/'\n",
    "\n",
    "X_big=np.load(data_path+'X_big.npy')\n",
    "y_big=np.load(data_path+'y_big.npy')\n",
    "\n",
    "print X_big.shape\n",
    "print y_big.shape\n",
    "print X_big.dtype\n",
    "print y_big.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_big=y_big.astype(float)\n",
    "\n",
    "X_train=X_big[:2000]\n",
    "y_train=y_big[:2000]\n",
    "\n",
    "X_test=X_big[2000:]\n",
    "y_test=y_big[2000:]\n",
    "\n",
    "X_big=[]\n",
    "y_big=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_example=X_train[0]\n",
    "img_example=img_example+127\n",
    "img_example=img_example.astype(np.uint8)\n",
    "\n",
    "img_example=np.reshape(img_example,(30,20))\n",
    "\n",
    "cv2.imshow('restored',img_example)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 30, 20, 1) (398,)\n",
      "(1202, 30, 20, 1) (1202,)\n"
     ]
    }
   ],
   "source": [
    "rus = RandomUnderSampler()\n",
    "X_test_resampled, y_test_resampled = rus.fit_sample(X_test, y_test)\n",
    "X_train_resampled,y_train_resampled = rus.fit_sample(X_train, y_train)\n",
    "\n",
    "\n",
    "X_train_resampled=np.reshape(X_train_resampled,(-1,30,20,1))\n",
    "X_test_resampled=np.reshape(X_test_resampled,(-1,30,20,1))\n",
    "\n",
    "\n",
    "print X_test_resampled.shape,y_test_resampled.shape\n",
    "print X_train_resampled.shape,y_train_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1202 samples, validate on 398 samples\n",
      "Epoch 1/50\n",
      "1202/1202 [==============================] - 0s - loss: 2.9568 - acc: 0.5358 - val_loss: 0.8440 - val_acc: 0.5352\n",
      "Epoch 2/50\n",
      "1202/1202 [==============================] - 0s - loss: 1.6742 - acc: 0.5116 - val_loss: 0.7567 - val_acc: 0.5050\n",
      "Epoch 3/50\n",
      "1202/1202 [==============================] - 0s - loss: 1.1605 - acc: 0.5441 - val_loss: 0.7035 - val_acc: 0.5553\n",
      "Epoch 4/50\n",
      "1202/1202 [==============================] - 0s - loss: 1.0389 - acc: 0.5516 - val_loss: 0.6852 - val_acc: 0.5879\n",
      "Epoch 5/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.9798 - acc: 0.5616 - val_loss: 0.6651 - val_acc: 0.6005\n",
      "Epoch 6/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.9143 - acc: 0.5774 - val_loss: 0.6573 - val_acc: 0.5854\n",
      "Epoch 7/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.8656 - acc: 0.5749 - val_loss: 0.6293 - val_acc: 0.6131\n",
      "Epoch 8/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.8287 - acc: 0.5865 - val_loss: 0.6009 - val_acc: 0.6533\n",
      "Epoch 9/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.7906 - acc: 0.6256 - val_loss: 0.5891 - val_acc: 0.6658\n",
      "Epoch 10/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.7483 - acc: 0.6664 - val_loss: 0.5457 - val_acc: 0.7010\n",
      "Epoch 11/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.7087 - acc: 0.6930 - val_loss: 0.5243 - val_acc: 0.7814\n",
      "Epoch 12/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.6866 - acc: 0.7163 - val_loss: 0.4887 - val_acc: 0.8266\n",
      "Epoch 13/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.6717 - acc: 0.7396 - val_loss: 0.4519 - val_acc: 0.8518\n",
      "Epoch 14/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.6384 - acc: 0.7671 - val_loss: 0.4413 - val_acc: 0.8467\n",
      "Epoch 15/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.6150 - acc: 0.7488 - val_loss: 0.4100 - val_acc: 0.8593\n",
      "Epoch 16/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.5880 - acc: 0.7829 - val_loss: 0.3957 - val_acc: 0.8593\n",
      "Epoch 17/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.5854 - acc: 0.7970 - val_loss: 0.3590 - val_acc: 0.8894\n",
      "Epoch 18/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.5606 - acc: 0.8178 - val_loss: 0.3445 - val_acc: 0.9196\n",
      "Epoch 19/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.5264 - acc: 0.8319 - val_loss: 0.3384 - val_acc: 0.9196\n",
      "Epoch 20/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.5199 - acc: 0.8494 - val_loss: 0.3372 - val_acc: 0.9221\n",
      "Epoch 21/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.4983 - acc: 0.8527 - val_loss: 0.3223 - val_acc: 0.9146\n",
      "Epoch 22/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.4668 - acc: 0.8744 - val_loss: 0.2996 - val_acc: 0.9246\n",
      "Epoch 23/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.4615 - acc: 0.8760 - val_loss: 0.2742 - val_acc: 0.9296\n",
      "Epoch 24/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.4641 - acc: 0.8794 - val_loss: 0.3098 - val_acc: 0.9171\n",
      "Epoch 25/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.4546 - acc: 0.8802 - val_loss: 0.2984 - val_acc: 0.9196\n",
      "Epoch 26/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.4263 - acc: 0.8927 - val_loss: 0.2594 - val_acc: 0.9347\n",
      "Epoch 27/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.4317 - acc: 0.8894 - val_loss: 0.2806 - val_acc: 0.9271\n",
      "Epoch 28/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.4112 - acc: 0.9035 - val_loss: 0.2511 - val_acc: 0.9397\n",
      "Epoch 29/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.3970 - acc: 0.9018 - val_loss: 0.2297 - val_acc: 0.9523\n",
      "Epoch 30/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.3879 - acc: 0.9085 - val_loss: 0.2176 - val_acc: 0.9472\n",
      "Epoch 31/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.3838 - acc: 0.9160 - val_loss: 0.2696 - val_acc: 0.9095\n",
      "Epoch 32/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.3622 - acc: 0.9143 - val_loss: 0.2150 - val_acc: 0.9347\n",
      "Epoch 33/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.3883 - acc: 0.9135 - val_loss: 0.2553 - val_acc: 0.9221\n",
      "Epoch 34/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.3814 - acc: 0.8993 - val_loss: 0.2322 - val_acc: 0.9322\n",
      "Epoch 35/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.3468 - acc: 0.9068 - val_loss: 0.1888 - val_acc: 0.9573\n",
      "Epoch 36/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.3198 - acc: 0.9285 - val_loss: 0.1793 - val_acc: 0.9523\n",
      "Epoch 37/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.3024 - acc: 0.9293 - val_loss: 0.1664 - val_acc: 0.9573\n",
      "Epoch 38/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.3173 - acc: 0.9243 - val_loss: 0.1768 - val_acc: 0.9422\n",
      "Epoch 39/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.3306 - acc: 0.9151 - val_loss: 0.2397 - val_acc: 0.9171\n",
      "Epoch 40/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.3097 - acc: 0.9260 - val_loss: 0.2379 - val_acc: 0.9146\n",
      "Epoch 41/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.3300 - acc: 0.9226 - val_loss: 0.2102 - val_acc: 0.9271\n",
      "Epoch 42/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.3028 - acc: 0.9326 - val_loss: 0.2193 - val_acc: 0.9246\n",
      "Epoch 43/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.3195 - acc: 0.9285 - val_loss: 0.1651 - val_acc: 0.9598\n",
      "Epoch 44/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.3067 - acc: 0.9235 - val_loss: 0.1803 - val_acc: 0.9548\n",
      "Epoch 45/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.3235 - acc: 0.9368 - val_loss: 0.1606 - val_acc: 0.9497\n",
      "Epoch 46/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.2718 - acc: 0.9318 - val_loss: 0.1623 - val_acc: 0.9422\n",
      "Epoch 47/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.3093 - acc: 0.9285 - val_loss: 0.1770 - val_acc: 0.9472\n",
      "Epoch 48/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.3096 - acc: 0.9235 - val_loss: 0.1625 - val_acc: 0.9598\n",
      "Epoch 49/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.2935 - acc: 0.9318 - val_loss: 0.1515 - val_acc: 0.9623\n",
      "Epoch 50/50\n",
      "1202/1202 [==============================] - 0s - loss: 0.2548 - acc: 0.9359 - val_loss: 0.1377 - val_acc: 0.9648\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(X_train_resampled, y_train_resampled, batch_size=32, nb_epoch=50, verbose=1, validation_data=(X_test_resampled,y_test_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'loss', 'val_acc', 'val_loss']\n"
     ]
    }
   ],
   "source": [
    "print(hist.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "val_acc=hist.history['val_acc']\n",
    "val_loss=hist.history['val_loss']\n",
    "\n",
    "print len(val_acc)\n",
    "print len(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(len(val_acc))],val_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/398 [====================>.........] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "test_res=model.evaluate(X_test_resampled,y_test_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13766624733581015, 0.96482412060301503]\n"
     ]
    }
   ],
   "source": [
    "print test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('neuro_models/neuro_model_0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601 601\n",
      "(1202,) 1202\n"
     ]
    }
   ],
   "source": [
    "cnt_zero=0\n",
    "cnt_one=0\n",
    "for i in y_train_resampled:\n",
    "    if i==0:\n",
    "        cnt_zero+=1\n",
    "    elif i==1:\n",
    "        cnt_one+=1\n",
    "print cnt_zero,cnt_one\n",
    "print y_train_resampled.shape,cnt_zero+cnt_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
